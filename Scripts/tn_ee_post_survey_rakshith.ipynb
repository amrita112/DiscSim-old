{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ba8c69",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac8084",
   "metadata": {},
   "source": [
    "We may have to run the following commands on Anaconda Prompt - after activating the DiscSim environment - to import some of the below packages\n",
    "\n",
    "pip install matplotlib\n",
    "pip install pandas\n",
    "pip install tqdm\n",
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb1ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import sep\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local modules\n",
    "import disc_score\n",
    "import binomial_confidence\n",
    "\n",
    "# Enable re-load of local modules every time they are called\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport numpy \n",
    "%aimport pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ac905",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a48531",
   "metadata": {},
   "source": [
    "ERROR FLAG: I added the ee_data.csv to the DiscSim folder and committed it to my branch. But when I ran the read_csv command and used your home_folder and filename codes to import the csv, it kept giving a \"File not found\" error. Just so that I do not waste time, I imported the data using the local path to the file. TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae9946ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following variables were found in the subordinate dataset:\n",
      "    identifier\n",
      "    student_id\n",
      "    Subject\n",
      "    1st question Level\n",
      "    1st level score\n",
      "    2nd question Level\n",
      "    2nd level score\n",
      "    3rd question Level\n",
      "    3rd level score\n",
      "    Cluster ID\n",
      "    School ID\n",
      "    district\n",
      "    Teacher User ID\n",
      "    class\n",
      "    baseline\n",
      "    Student Identifier\n"
     ]
    }
   ],
   "source": [
    "# Loading the subordinate dataset ee_data.csv\n",
    "#home_folder = 'Documents{0}CEGIS{0}DiscSim'.format(sep)\n",
    "sub_data = pd.read_csv(r\"C:\\Users\\Cegis\\Documents\\GitHub\\DiscSim\\ee_data.csv\")\n",
    "variables = sub_data.columns\n",
    "n_variables = len(variables)\n",
    "\n",
    "print('The following variables were found in the subordinate dataset:')\n",
    "for v in variables:\n",
    "    print('    {0}'.format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "455f2ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new column names are as follows: \n",
      "\n",
      "    ID\n",
      "    Student_ID\n",
      "    Subject\n",
      "    Sub_Q1_Level\n",
      "    Sub_Q1_Score\n",
      "    Sub_Q2_Level\n",
      "    Sub_Q2_Score\n",
      "    Sub_Q3_Level\n",
      "    Sub_Q3_Score\n",
      "    Cluster_ID\n",
      "    School_ID\n",
      "    District\n",
      "    Sub_ID\n",
      "    Stu_Class\n",
      "    Stu_Baseline_Level\n",
      "    Stu_Identifier\n"
     ]
    }
   ],
   "source": [
    "# Renaming the variables \n",
    "sub_data.columns = ['ID', 'Student_ID', 'Subject', 'Sub_Q1_Level', 'Sub_Q1_Score', 'Sub_Q2_Level', 'Sub_Q2_Score', 'Sub_Q3_Level', 'Sub_Q3_Score', 'Cluster_ID', 'School_ID', 'District', 'Sub_ID', 'Stu_Class', 'Stu_Baseline_Level', 'Stu_Identifier']\n",
    "variables = sub_data.columns\n",
    "print(\"The new column names are as follows: \\n\")\n",
    "for v in variables:\n",
    "    print('    {0}'.format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7babbb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following variables were found in the supervisor dataset:\n",
      "    UID\n",
      "    district\n",
      "    block id\n",
      "    cluster id\n",
      "    Student Identifier\n",
      "    school id\n",
      "    subject\n",
      "    class\n",
      "    baseline\n",
      "    1st question Level\n",
      "    1st level score\n",
      "    2nd question Level\n",
      "    2nd level score\n",
      "    3rd question Level\n",
      "    3rd level score\n",
      "    Admin User ID\n"
     ]
    }
   ],
   "source": [
    "# Loading the supervisor dataset ee_ees_data.csv\n",
    "sup_data = pd.read_csv(r\"C:\\Users\\Cegis\\Documents\\GitHub\\DiscSim\\ee_ees_data.csv\")\n",
    "variables = sup_data.columns\n",
    "n_variables = len(variables)\n",
    "\n",
    "print('The following variables were found in the supervisor dataset:')\n",
    "for v in variables:\n",
    "    print('    {0}'.format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f0d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new column names are as follows: \n",
      "\n",
      "    ID\n",
      "    District\n",
      "    Block_ID\n",
      "    Cluster_ID\n",
      "    Stu_Identifier\n",
      "    School_ID\n",
      "    Subject\n",
      "    Stu_Class\n",
      "    Stu_Baseline_Level\n",
      "    Sup_Q1_Level\n",
      "    Sup_Q1_Score\n",
      "    Sup_Q2_Level\n",
      "    Sup_Q2_Score\n",
      "    Sup_Q3_Level\n",
      "    Sup_Q3_Score\n",
      "    Sup_ID\n"
     ]
    }
   ],
   "source": [
    "# Renaming the variables \n",
    "sup_data.columns = ['ID', 'District', 'Block_ID', 'Cluster_ID', 'Stu_Identifier', 'School_ID', 'Subject', 'Stu_Class','Stu_Baseline_Level', 'Sup_Q1_Level', 'Sup_Q1_Score', 'Sup_Q2_Level', 'Sup_Q2_Score', 'Sup_Q3_Level', 'Sup_Q3_Score', 'Sup_ID']\n",
    "variables = sup_data.columns\n",
    "print(\"The new column names are as follows: \\n\")\n",
    "for v in variables:\n",
    "    print('    {0}'.format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f794f5",
   "metadata": {},
   "source": [
    "# Merging the subordinate and supervisor datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c97cea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in supervisor dataset: \n",
      "13577\n",
      "\n",
      "\n",
      "Number of observations in subordinate dataset: \n",
      "166850\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in supervisor dataset: \")\n",
    "print(len(sup_data))\n",
    "print(\"\\n\")\n",
    "print(\"Number of observations in subordinate dataset: \")\n",
    "print(len(sub_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19d1949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The supervisor and subordinate datasets have been merged\n",
      "Number of observations in the merged dataset: \n",
      "13577\n",
      "The variables in the merged dataset are as follows: \n",
      "    ID\n",
      "    District_x\n",
      "    Block_ID\n",
      "    Cluster_ID_x\n",
      "    Stu_Identifier_x\n",
      "    School_ID_x\n",
      "    Subject_x\n",
      "    Stu_Class_x\n",
      "    Stu_Baseline_Level_x\n",
      "    Sup_Q1_Level\n",
      "    Sup_Q1_Score\n",
      "    Sup_Q2_Level\n",
      "    Sup_Q2_Score\n",
      "    Sup_Q3_Level\n",
      "    Sup_Q3_Score\n",
      "    Sup_ID\n",
      "    Student_ID\n",
      "    Subject_y\n",
      "    Sub_Q1_Level\n",
      "    Sub_Q1_Score\n",
      "    Sub_Q2_Level\n",
      "    Sub_Q2_Score\n",
      "    Sub_Q3_Level\n",
      "    Sub_Q3_Score\n",
      "    Cluster_ID_y\n",
      "    School_ID_y\n",
      "    District_y\n",
      "    Sub_ID\n",
      "    Stu_Class_y\n",
      "    Stu_Baseline_Level_y\n",
      "    Stu_Identifier_y\n"
     ]
    }
   ],
   "source": [
    "# Performing an inner join to merge the subordinate \n",
    "data = pd.merge(sup_data, sub_data, on='ID')\n",
    "print(\"The supervisor and subordinate datasets have been merged\")\n",
    "print(\"Number of observations in the merged dataset: \")\n",
    "print(len(data))\n",
    "print(\"The variables in the merged dataset are as follows: \")\n",
    "variables = data.columns\n",
    "for v in variables:\n",
    "    print('    {0}'.format(v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdbfccd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID\n",
      "    District\n",
      "    Block_ID\n",
      "    Cluster_ID\n",
      "    Stu_Identifier\n",
      "    School_ID\n",
      "    Subject\n",
      "    Stu_Class\n",
      "    Stu_Baseline_Level\n",
      "    Sup_Q1_Level\n",
      "    Sup_Q1_Score\n",
      "    Sup_Q2_Level\n",
      "    Sup_Q2_Score\n",
      "    Sup_Q3_Level\n",
      "    Sup_Q3_Score\n",
      "    Sup_ID\n",
      "    Student_ID\n",
      "    Sub_Q1_Level\n",
      "    Sub_Q1_Score\n",
      "    Sub_Q2_Level\n",
      "    Sub_Q2_Score\n",
      "    Sub_Q3_Level\n",
      "    Sub_Q3_Score\n",
      "    Sub_ID\n"
     ]
    }
   ],
   "source": [
    "# Dropping unnecessary rows from the merged dataset\n",
    "data.pop('Cluster_ID_y')\n",
    "data.pop('School_ID_y')\n",
    "data.pop('District_y')\n",
    "data.pop('Stu_Class_y')\n",
    "data.pop('Stu_Baseline_Level_y')\n",
    "data.pop('Stu_Identifier_y')\n",
    "data.pop('Subject_y')\n",
    "\n",
    "# Renaming variables in the merged dataset\n",
    "data.rename(columns = {'District_x':'District'}, inplace = True)\n",
    "data.rename(columns = {'Cluster_ID_x':'Cluster_ID'}, inplace = True)\n",
    "data.rename(columns = {'Stu_Identifier_x':'Stu_Identifier'}, inplace = True)\n",
    "data.rename(columns = {'School_ID_x':'School_ID'}, inplace = True)\n",
    "data.rename(columns = {'Subject_x':'Subject'}, inplace = True)\n",
    "data.rename(columns = {'Stu_Class_x':'Stu_Class'}, inplace = True)\n",
    "data.rename(columns = {'Stu_Baseline_Level_x':'Stu_Baseline_Level'}, inplace = True)\n",
    "\n",
    "variables = data.columns\n",
    "for v in variables:\n",
    "    print('    {0}'.format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fbe66c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged dataset looks like this: \n",
      " \n",
      "\n",
      "            ID      District  Block_ID   Cluster_ID  Stu_Identifier  \\\n",
      "0  022724217_1  CHENGALPATTU         5  33030600402        22724217   \n",
      "1  022724217_3  CHENGALPATTU         5  33030600402        22724217   \n",
      "\n",
      "     School_ID  Subject  Stu_Class Stu_Baseline_Level Sup_Q1_Level  ...  \\\n",
      "0  33030600201  English          3              Malar        Malar  ...   \n",
      "1  33030600201    Tamil          3              Malar        Malar  ...   \n",
      "\n",
      "   Sup_Q3_Score   Sup_ID  Student_ID Sub_Q1_Level  Sub_Q1_Score  Sub_Q2_Level  \\\n",
      "0           NaN  3000135  2022724217        Malar            10           NaN   \n",
      "1           NaN  3000135  2022724217        Malar            10           NaN   \n",
      "\n",
      "   Sub_Q2_Score Sub_Q3_Level  Sub_Q3_Score    Sub_ID  \n",
      "0           NaN          NaN           NaN  20023719  \n",
      "1           NaN          NaN           NaN  20023719  \n",
      "\n",
      "[2 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"The merged dataset looks like this: \\n \\n\")\n",
    "print(data.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
